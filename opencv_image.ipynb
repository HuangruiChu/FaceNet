{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opencv之人脸仿射\n",
    "## 储黄瑞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 该代码实现利用人脸的五点仿射变换实现人脸对齐\n",
    "## 具体就是首先使用mtcnn检测算法检测出人脸区域，并得到lanmarks关键点坐标和检测框坐标之后对人脸区域外扩60%，然后对该外扩后的区域重新得到关键点，进行五点仿射变换得到即可。\n",
    "## 参考链接：https://blog.csdn.net/oTengYue/article/details/79278572\n",
    "## 如果图片中检测到多张人脸，或者未检测到人脸，那我就把原图复制过去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基本的引入，按字母表排序\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from numpy.random import uniform\n",
    "import os\n",
    "from os import path as osp\n",
    "import PIL\n",
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "from random import shuffle\n",
    "import sys\n",
    "sys.path.append(r'py')\n",
    "import time\n",
    "#torch部分的import\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as opt\n",
    "#from tensorboardX import SummaryWriter\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MTCNN_detector import MtcnnDetector,vis_face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTCNN  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(P_Net, self).__init__()\n",
    "        self.pre_layer = nn.Sequential(\n",
    "            # 12x12x3\n",
    "            nn.Conv2d(3, 10, kernel_size=3, stride=1),  # conv1\n",
    "            nn.PReLU(),  # PReLU1\n",
    "            # 10x10x10\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # pool1\n",
    "            # 5x5x10\n",
    "            nn.Conv2d(10, 16, kernel_size=3, stride=1),  # conv2\n",
    "            # 3x3x16\n",
    "            nn.PReLU(),  # PReLU2\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1),  # conv3\n",
    "            # 1x1x32\n",
    "            nn.PReLU()  # PReLU3\n",
    "        )\n",
    "        # detection\n",
    "        self.conv4_1 = nn.Conv2d(32, 1, kernel_size=1, stride=1)\n",
    "        # bounding box regresion\n",
    "        self.conv4_2 = nn.Conv2d(32, 4, kernel_size=1, stride=1)\n",
    "        # landmark localization\n",
    "        self.conv4_3 = nn.Conv2d(32, 10, kernel_size=1, stride=1)\n",
    "        # weight initiation with xavier\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre_layer(x)\n",
    "        det = torch.sigmoid(self.conv4_1(x))\n",
    "        box = self.conv4_2(x)\n",
    "        #landmark = self.conv4_3(x)\n",
    "        # det:[,2,1,1], box:[,4,1,1], landmark:[,10,1,1]\n",
    "        return det, box#, landmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(R_Net, self).__init__()\n",
    "        self.pre_layer = nn.Sequential(\n",
    "            # 24x24x3\n",
    "            nn.Conv2d(3, 28, kernel_size=3, stride=1),  # conv1\n",
    "            nn.PReLU(),  # prelu1\n",
    "            # 22x22x28\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # pool1\n",
    "            # 10x10x28\n",
    "            nn.Conv2d(28, 48, kernel_size=3, stride=1),  # conv2\n",
    "            nn.PReLU(),  # prelu2\n",
    "            # 8x8x48\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # pool2\n",
    "            # 3x3x48\n",
    "            nn.Conv2d(48, 64, kernel_size=2, stride=1),  # conv3\n",
    "            # 2x2x64\n",
    "            nn.PReLU()  # prelu3\n",
    "        )\n",
    "        # 2x2x64\n",
    "        self.conv4 = nn.Linear(64 * 2 * 2, 128)  # conv4\n",
    "        # 128\n",
    "        self.prelu4 = nn.PReLU()  # prelu4\n",
    "        # detection\n",
    "        self.conv5_1 = nn.Linear(128, 1)\n",
    "        # bounding box regression\n",
    "        self.conv5_2 = nn.Linear(128, 4)\n",
    "        # lanbmark localization\n",
    "        self.conv5_3 = nn.Linear(128, 10)\n",
    "        # weight initiation weih xavier\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre_layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.conv4(x)\n",
    "        x = self.prelu4(x)\n",
    "        det = torch.sigmoid(self.conv5_1(x))\n",
    "        #det = F.softmax(self.conv5_1(x), dim=1)#也可以试试softmax呀\n",
    "        box = self.conv5_2(x)\n",
    "        #landmark = self.conv5_3(x)\n",
    "        return det, box#, landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class O_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(O_Net, self).__init__()\n",
    "        self.pre_layer = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1),  # conv1\n",
    "            nn.PReLU(),  # prelu1\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # pool1\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1),  # conv2\n",
    "            nn.PReLU(),  # prelu2\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # pool2\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),  # conv3\n",
    "            nn.PReLU(),  # prelu3\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # pool3\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=1),  # conv4\n",
    "            nn.PReLU()  # prelu4\n",
    "        )\n",
    "        self.conv5 = nn.Linear(128 * 2 * 2, 256)  # conv5\n",
    "        self.prelu5 = nn.PReLU()  # prelu5\n",
    "        # detection\n",
    "        self.conv6_1 = nn.Linear(256, 1)\n",
    "        # bounding box regression\n",
    "        self.conv6_2 = nn.Linear(256, 4)\n",
    "        # lanbmark localization\n",
    "        self.conv6_3 = nn.Linear(256, 10)\n",
    "        # weight initiation weih xavier\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre_layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.conv5(x)\n",
    "        x = self.prelu5(x)\n",
    "        # detection\n",
    "        det = torch.sigmoid(self.conv6_1(x))\n",
    "        box = self.conv6_2(x)\n",
    "        landmark = self.conv6_3(x)\n",
    "        return det, box, landmark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相关的一些functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 1. 根据网络层的不同定义不同的初始化方式     \n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        #nn.init.constant_(m.bias, 0) bias不要全初始化为0\n",
    "        nn.init.normal_(m.bias, mean=0, std=1)\n",
    "    # 也可以判断是否为conv2d，使用相应的初始化方式 \n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "     # 是否为批归一化层\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "#使用这样的初始化后，模型的初始表现确实好了些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(save_folder, net_name):\n",
    "    # pnet, rnet, onet = P_Net(), R_Net(), O_Net()\n",
    "    net_list = {'pnet': P_Net(), 'rnet': R_Net(), 'onet': O_Net()}\n",
    "\n",
    "    try:\n",
    "        net = net_list[net_name].to(device)\n",
    "        try:\n",
    "            print('===> loading the saved net weights...')\n",
    "            _ = osp.join(save_folder, net_name + '.pkl')\n",
    "            print('===> check {} saved path({}):{}'.format(net_name, _, osp.exists(_)))\n",
    "            net.load_state_dict(torch.load(_, map_location=device))\n",
    "            return net  # , rnet, onet\n",
    "        except Exception:\n",
    "            print('*** fail to load the saved net weights!')\n",
    "            return net\n",
    "    except Exception:\n",
    "        print('*** Net name wrong!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用OpenCV实现仿射人脸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最终的人脸对齐图像尺寸分为112x112，并分别对应结果图像中的两组仿射变换目标点,如下所示\n",
    "imgSize2 = [112,112]\n",
    "coord5point2 = [[30.2946+8.0000, 51.6963], # 112x112的目标点\n",
    "               [65.5318+8.0000, 51.6963],\n",
    "               [48.0252+8.0000, 71.7366],\n",
    "               [33.5493+8.0000, 92.3655],\n",
    "               [62.7299+8.0000, 92.3655]]\n",
    "\n",
    "def transformation_from_points(points1, points2):\n",
    "    '''0 - 先确定是float数据类型 '''\n",
    "    points1 = points1.astype(np.float64)\n",
    "    points2 = points2.astype(np.float64)\n",
    "    '''1 - 消除平移的影响 '''\n",
    "    c1 = np.mean(points1, axis=0)\n",
    "    c2 = np.mean(points2, axis=0)\n",
    "    points1 -= c1\n",
    "    points2 -= c2\n",
    "    '''2 - 消除缩放的影响 '''\n",
    "    s1 = np.std(points1)\n",
    "    s2 = np.std(points2)\n",
    "    points1 /= s1\n",
    "    points2 /= s2\n",
    "    '''3 - 计算矩阵M=BA^T；对矩阵M进行SVD分解；计算得到R '''\n",
    "    U, S, Vt = np.linalg.svd(points1.T * points2)\n",
    "    R = np.dot(U, Vt)\n",
    "    '''4 - 构建仿射变换矩阵 '''\n",
    "    s = s2/s1\n",
    "    sR = s*R\n",
    "    c1 = c1.reshape(2,1)\n",
    "    c2 = c2.reshape(2,1)\n",
    "    T = c2 - np.dot(sR,c1) # 模板人脸的中心位置减去 需要对齐的中心位置（经过旋转和缩放之后）\n",
    "    trans_mat = np.hstack([sR,T])   # 2x3\n",
    "    return trans_mat\n",
    "\n",
    "def warp_im(img_im, orgi_landmarks,tar_landmarks):\n",
    "    pts1 = np.float64(np.matrix([[point[0], point[1]] for point in orgi_landmarks]))\n",
    "    pts2 = np.float64(np.matrix([[point[0], point[1]] for point in tar_landmarks]))\n",
    "    M = transformation_from_points(pts1, pts2)\n",
    "    dst = cv2.warpAffine(img_im, M[:2], (img_im.shape[1], img_im.shape[0]),borderMode=cv2.BORDER_TRANSPARENT)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#为处理lfw数据集改编版，输出是142*142,在datapreprocess的时候可以resize一下。\n",
    "def opencv_image(pic_path):\n",
    "    # 对一个路径下的所有图片进行对齐，并保存在new_picture_path下\n",
    "    new_pic_path=\"Cropped_images\"\n",
    "    #加载mtcnn参数\n",
    "    save_folder=\"CHUHR\"\n",
    "    pnet= load_net(save_folder,'pnet')\n",
    "    rnet= load_net(save_folder,'rnet')\n",
    "    onet= load_net(save_folder,'onet')\n",
    "    mtcnn_detector = MtcnnDetector(pnet=pnet,rnet=rnet,onet=onet,min_face_size=12,threshold=[0.1,0.5,0.9])\n",
    "    count=0\n",
    "    people_name_list = os.listdir(pic_path)\n",
    "    people_name_list.sort()\n",
    "    for people_name in people_name_list:\n",
    "        pic_name_list=os.listdir(os.path.join(pic_path,people_name))\n",
    "        for every_pic_name in pic_name_list:\n",
    "            image_path=os.path.join(pic_path,people_name,every_pic_name)\n",
    "            img_im = cv2.imread(image_path)       \n",
    "            if img_im is None:\n",
    "                continue\n",
    "            else:\n",
    "                img = Image.open(image_path)\n",
    "                #关键点检测\n",
    "                bounding_boxes, points= mtcnn_detector.detect_face(img)\n",
    "                shape = img_im.shape\n",
    "                height = shape[0]\n",
    "                width = shape[1]\n",
    "                # 处理该张图片中的每个框\n",
    "                if bounding_boxes.shape[0] !=1:\n",
    "                    img_save_path=os.path.join(new_pic_path ,people_name)\n",
    "                    cv2.imwrite(img_save_path+\"/\"+every_pic_name[:-4]+'.jpg',img_im)\n",
    "                else:\n",
    "                    for i in range(bounding_boxes.shape[0]):  # 根据行号得到每张图片有多少个回归框\n",
    "                        x1, y1, x2, y2 = int(bounding_boxes[i][0]), \\\n",
    "                                         int(bounding_boxes[i][1]), \\\n",
    "                                         int(bounding_boxes[i][2]), \\\n",
    "                                         int(bounding_boxes[i][3])\n",
    "                        # 外扩大60%，防止对齐后人脸出现过多黑边\n",
    "                        new_x1 = max(int(1.30 * x1 - 0.30 * x2),0)\n",
    "                        new_x2 = min(int(1.30 * x2 - 0.30 * x1),width-1)\n",
    "                        new_y1 = max(int(1.30 * y1 - 0.30 * y2),0)\n",
    "                        new_y2 = min(int(1.30 * y2 - 0.30 * y1),height-1)\n",
    "\n",
    "\n",
    "                        landmarks_one = points[i, :]\n",
    "                        landmarks_one = landmarks_one.reshape((5, 2))\n",
    "\n",
    "                        # 得到原始图中关键点坐标\n",
    "                        left_eye_x = landmarks_one[0][0]\n",
    "                        right_eye_x = landmarks_one[1][0]\n",
    "                        nose_x = landmarks_one[2][0]\n",
    "                        left_mouth_x = landmarks_one[3][0]\n",
    "                        right_mouth_x = landmarks_one[4][0]\n",
    "                        left_eye_y = landmarks_one[1][1]\n",
    "                        right_eye_y = landmarks_one[0][1]\n",
    "                        nose_y = landmarks_one[2][1]\n",
    "                        left_mouth_y = landmarks_one[3][1]\n",
    "                        right_mouth_y = landmarks_one[4][1]\n",
    "\n",
    "                        # 得到外扩60%后图中关键点坐标\n",
    "                        new_left_eye_x = left_eye_x - new_x1\n",
    "                        new_right_eye_x = right_eye_x - new_x1\n",
    "                        new_nose_x = nose_x - new_x1\n",
    "                        new_left_mouth_x = left_mouth_x - new_x1\n",
    "                        new_right_mouth_x = right_mouth_x - new_x1\n",
    "                        new_left_eye_y = left_eye_y - new_y1\n",
    "                        new_right_eye_y = right_eye_y - new_y1\n",
    "                        new_nose_y = nose_y - new_y1\n",
    "                        new_left_mouth_y = left_mouth_y - new_y1\n",
    "                        new_right_mouth_y = right_mouth_y - new_y1\n",
    "\n",
    "                        face_landmarks = [[new_left_eye_x,new_left_eye_y], # 在扩大60%人脸图中关键点坐标\n",
    "                                          [new_right_eye_x,new_right_eye_y],\n",
    "                                          [new_nose_x,new_nose_y],\n",
    "                                          [new_left_mouth_x,new_left_mouth_y],\n",
    "                                          [new_right_mouth_x,new_right_mouth_y]]\n",
    "                        face = img_im[new_y1: new_y2, new_x1: new_x2] # 扩大60%的人脸区域\n",
    "                        dst2 = warp_im(face,face_landmarks,coord5point2) # 112x112对齐后尺寸\n",
    "                        crop_im2 = dst2[0:imgSize2[0]+30,0:imgSize2[1]+30]#最后扩大取值区域，防止截取的人脸不完整。\n",
    "                        img_save_path=os.path.join(new_pic_path ,people_name)\n",
    "                        if not os.path.exists(img_save_path):\n",
    "                            os.makedirs(img_save_path)\n",
    "                        cv2.imwrite(img_save_path+\"/\"+every_pic_name[:-4]+'.jpg',crop_im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = os.listdir(\"Cropped_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5749"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
